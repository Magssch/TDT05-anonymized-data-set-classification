{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit ('venv': venv)"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"82f34db40c108bacdf80cee8c03ed548c4970ecdf3b7dfe6a243b9d12513bd47"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Data exploration"],"metadata":{}},{"cell_type":"code","execution_count":38,"source":["# Imports\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from math import pow\n","\n","print('Tensorflow version:', tf.__version__)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow version: 2.6.0\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:49.396641Z","iopub.execute_input":"2021-09-28T14:03:49.396917Z","iopub.status.idle":"2021-09-28T14:03:49.402713Z","shell.execute_reply.started":"2021-09-28T14:03:49.396891Z","shell.execute_reply":"2021-09-28T14:03:49.40199Z"},"trusted":true}},{"cell_type":"code","execution_count":39,"source":["# Load data\n","training_data = pd.read_csv('../input/tdt05-2021-challenge-2/challenge2_train.csv', index_col=0)\n","X_test = pd.read_csv('../input/tdt05-2021-challenge-2/challenge2_test.csv', index_col=0)\n","\n","print('Shape training:', training_data.shape)\n","print('Shape test:', X_test.shape)\n","summary_statistics = pd.DataFrame(\n","    {\n","        '#nan': training_data.isnull().sum(axis = 0),\n","        'categories': training_data.nunique(), \n","        'dtype': training_data.dtypes\n","    }, \n","    index=training_data.columns,\n",")\n","\n","print(summary_statistics)\n","training_data.head(5)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Shape training: (50000, 30)\n","Shape test: (50000, 29)\n","         #nan  categories    dtype\n","target      0           2    int64\n","f0       1459           2  float64\n","f1       1487         190   object\n","f2       1439           6   object\n","f3       1488           3  float64\n","f4       1498           2   object\n","f5      11617          13  float64\n","f6       1490           2  float64\n","f7       1525           6  float64\n","f8       1490        2177   object\n","f9       1489           5   object\n","f10      1501          26   object\n","f11       145        7633  float64\n","f12      1541         222   object\n","f13      1447          15   object\n","f14      1451        1204   object\n","f15      1477         222   object\n","f16      1460          12  float64\n","f17      9762       19209  float64\n","f18      1556           6   object\n","f19      1437           6  float64\n","f20      1464           4  float64\n","f21      1510           7  float64\n","f22      1513           3   object\n","f23      1516        1495   object\n","f24      2696        4148  float64\n","f25      1537           2   object\n","f26      1474           2   object\n","f27      1464           4  float64\n","f28     13112        8060  float64\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>f0</th>\n","      <th>f1</th>\n","      <th>f2</th>\n","      <th>f3</th>\n","      <th>f4</th>\n","      <th>f5</th>\n","      <th>f6</th>\n","      <th>f7</th>\n","      <th>f8</th>\n","      <th>...</th>\n","      <th>f19</th>\n","      <th>f20</th>\n","      <th>f21</th>\n","      <th>f22</th>\n","      <th>f23</th>\n","      <th>f24</th>\n","      <th>f25</th>\n","      <th>f26</th>\n","      <th>f27</th>\n","      <th>f28</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>gL</td>\n","      <td>e</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>96ae67d3e</td>\n","      <td>...</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>R</td>\n","      <td>328b0cf4e</td>\n","      <td>0.834041</td>\n","      <td>T</td>\n","      <td>N</td>\n","      <td>1.0</td>\n","      <td>14.2364</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>Rj</td>\n","      <td>c</td>\n","      <td>1.0</td>\n","      <td>A</td>\n","      <td>7.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>9fcf422f2</td>\n","      <td>...</td>\n","      <td>0.4</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>328b0cf4e</td>\n","      <td>0.686021</td>\n","      <td>T</td>\n","      <td>N</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>In</td>\n","      <td>a</td>\n","      <td>1.0</td>\n","      <td>A</td>\n","      <td>10.0</td>\n","      <td>1.0</td>\n","      <td>6.0</td>\n","      <td>a5adff44e</td>\n","      <td>...</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>G</td>\n","      <td>0c67fcbbd</td>\n","      <td>1.141271</td>\n","      <td>T</td>\n","      <td>N</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>rA</td>\n","      <td>c</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>7.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>15c90ab2e</td>\n","      <td>...</td>\n","      <td>0.6</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>G</td>\n","      <td>fee4e3007</td>\n","      <td>0.662382</td>\n","      <td>T</td>\n","      <td>N</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>pE</td>\n","      <td>c</td>\n","      <td>3.0</td>\n","      <td>A</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>6.0</td>\n","      <td>b36490559</td>\n","      <td>...</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>B</td>\n","      <td>587e040bd</td>\n","      <td>-1.000000</td>\n","      <td>T</td>\n","      <td>N</td>\n","      <td>1.0</td>\n","      <td>13.9537</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 30 columns</p>\n","</div>"],"text/plain":["    target   f0  f1 f2   f3 f4    f5   f6   f7         f8  ...  f19  f20  f21  \\\n","id                                                         ...                  \n","0        0  1.0  gL  e  3.0  A   NaN  0.0  6.0  96ae67d3e  ...  0.5  0.0  3.0   \n","1        0  0.0  Rj  c  1.0  A   7.0  1.0  4.0  9fcf422f2  ...  0.4  0.0  1.0   \n","2        0  NaN  In  a  1.0  A  10.0  1.0  6.0  a5adff44e  ...  0.5  1.0  3.0   \n","3        1  1.0  rA  c  3.0  A   7.0  1.0  1.0  15c90ab2e  ...  0.6  1.0  1.0   \n","4        0  1.0  pE  c  3.0  A   7.0  0.0  6.0  b36490559  ...  0.5  0.0  1.0   \n","\n","    f22        f23       f24 f25  f26  f27      f28  \n","id                                                   \n","0     R  328b0cf4e  0.834041   T    N  1.0  14.2364  \n","1   NaN  328b0cf4e  0.686021   T    N  1.0      NaN  \n","2     G  0c67fcbbd  1.141271   T    N  3.0      NaN  \n","3     G  fee4e3007  0.662382   T    N  3.0      NaN  \n","4     B  587e040bd -1.000000   T    N  1.0  13.9537  \n","\n","[5 rows x 30 columns]"]},"metadata":{},"execution_count":39}],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:49.41746Z","iopub.execute_input":"2021-09-28T14:03:49.417771Z","iopub.status.idle":"2021-09-28T14:03:50.031484Z","shell.execute_reply.started":"2021-09-28T14:03:49.417738Z","shell.execute_reply":"2021-09-28T14:03:50.030533Z"},"trusted":true}},{"cell_type":"markdown","source":["## Feature description\n","- target: 0 or 1 -> binary classification\n","- f0: 0.0 or 1.0\n","- f1: weird combination of lower and uppercase letters. 173 unique pairs (categories) with occurences from ranging from 8 to 874\n","- f2: letters a-f with distribution (a=24%, b=11%, c=14%, d=16%, e=11%, f=21%, null=3%)\n","- f3: 1.0, 2.0, or 3.0 with distribution (1.0=38%, 2.0=26%, 3.0=33%, null=3%)\n","- f4: A or B with distribution (A=88%, B=9%, null=3%)\n","- f5: -1 to 11 with distribution (~0%, 1%, ~0%, ~0%, 1%, 3%, 2%, 8%, 23%, 2%, 3%, 6%, 27%, null=23%)"],"metadata":{}},{"cell_type":"markdown","source":["The features labeled:\n","- f8 \n","- f12 \n","- f14 \n","- f15 \n","- f23\n","\n","All seem to be hexadecimal. These might just be an id of sorts, or they can be the hex representation of a number.  \n","An idea can be to covert these into decimal and see if they are important somehow."],"metadata":{}},{"cell_type":"code","execution_count":40,"source":["hexadecimal_columns = ['f8', 'f12', 'f14', 'f15', 'f23']\n","merged_datasets = pd.concat([training_dataraining_data, X_test])[hexadecimal_columns]\n","\n","merged_statistics = pd.DataFrame(\n","    {\n","        '#categories before merge': training_data.nunique(), \n","        '#categories after merge': merged_datasets.nunique(), \n","    }, \n","    index=merged_datasets.columns,\n",")\n","\n","print(merged_statistics)"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'training_dataraining_data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_15423/3674461173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhexadecimal_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'f8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f12'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f14'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f15'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f23'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmerged_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_dataraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhexadecimal_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m merged_statistics = pd.DataFrame(\n\u001b[1;32m      5\u001b[0m     {\n","\u001b[0;31mNameError\u001b[0m: name 'training_dataraining_data' is not defined"]}],"metadata":{}},{"cell_type":"markdown","source":["## Data cleaning\n","Data cleaning consists of the following steps\n","- Removal of unwanted observations\n","- Fixing structural errors\n","- Managing unwanted outliers\n","- Handeling missing data"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Partition the data\n","X = training_data.drop(columns=['target']).copy()\n","y = training_data[['target']].copy()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:50.033801Z","iopub.execute_input":"2021-09-28T14:03:50.034125Z","iopub.status.idle":"2021-09-28T14:03:50.059448Z","shell.execute_reply.started":"2021-09-28T14:03:50.034085Z","shell.execute_reply":"2021-09-28T14:03:50.058571Z"},"trusted":true}},{"cell_type":"markdown","source":["### Making the data types *correct*\n","- Boolean features should be `boolean`\n","- Categorical features should be `categorical`\n","- Numerical features should be `int64` or `float64`"],"metadata":{}},{"cell_type":"markdown","source":["### Dealing with missing values\n","XBoost and CatBoost handles missing data differently. This needs to be taken into account before training.\n","- XGBoost: missing values should be zero\n","- CatBoost: missing values should be way off the distribution, like -999"],"metadata":{}},{"cell_type":"code","execution_count":43,"source":["# CatBoost specific preprocessing\n","fill_value = -999\n","\n","X.fillna(fill_value, inplace=True), X_test.fillna(fill_value, inplace=True)\n","\n","X['f0'] = X['f0'].astype(str)\n","X_test['f0'] = X_test['f0'].astype(str)\n","\n","missing_values = pd.DataFrame(\n","    {\n","        '#nan_train': X.isnull().sum(axis = 0),\n","        '#nan_test': X.isnull().sum(axis = 0),\n","    }, \n","    index=X.columns,\n",")\n","print(missing_values)"],"outputs":[{"output_type":"stream","name":"stdout","text":["     #nan_train  #nan_test\n","f0            0          0\n","f1            0          0\n","f2            0          0\n","f3            0          0\n","f4            0          0\n","f5            0          0\n","f6            0          0\n","f7            0          0\n","f8            0          0\n","f9            0          0\n","f10           0          0\n","f11           0          0\n","f12           0          0\n","f13           0          0\n","f14           0          0\n","f15           0          0\n","f16           0          0\n","f17           0          0\n","f18           0          0\n","f19           0          0\n","f20           0          0\n","f21           0          0\n","f22           0          0\n","f23           0          0\n","f24           0          0\n","f25           0          0\n","f26           0          0\n","f27           0          0\n","f28           0          0\n"]}],"metadata":{}},{"cell_type":"markdown","source":["## CatBoost"],"metadata":{}},{"cell_type":"code","execution_count":41,"source":["from catboost import CatBoostClassifier, Pool, metrics, cv\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# categorical_features_indices = np.where(X.dtypes != np.float)[0]\n","categorical_features_indices = [0, 1, 2, 4, 8, 9, 10, 12, 13, 14, 15, 18, 22, 23, 25, 26]\n","\n","X['f0'] = X['f0'].astype(str)\n","X_test['f0'] = X_test['f0'].astype(str)\n","\n","# X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.75, random_state=42)\n","\n","model = CatBoostClassifier(\n","    custom_loss=[metrics.Accuracy()],\n","    random_seed=42,\n","    logging_level='Silent'\n",")\n","\n","model.fit(\n","    X, y,\n","    cat_features=categorical_features_indices,\n","    # eval_set=(X_validation, y_validation),\n","    # plot=True\n",")\n","\n","# cv_params = model.get_params()\n","# cv_params.update({\n","#     'loss_function': metrics.Logloss()\n","# })\n","\n","# cv_data = cv(\n","#     Pool(X, y, cat_features=categorical_features_indices),\n","#     cv_params,\n","#     plot=True\n","# )\n","\n","print(model.get_best_score())\n"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x7f02c1f168b0>"]},"metadata":{},"execution_count":41}],"metadata":{}},{"cell_type":"markdown","source":["## Make predictions\n","\n","Make predictions from `X_test` and save to file."],"metadata":{}},{"cell_type":"code","execution_count":57,"source":["y_pred = model.predict(X_test, prediction_type='Probability')\n","print(model.get_best_score())\n","predictions = pd.DataFrame({'id': X_test.index, 'target': y_pred[:,1]})\n","\n","predictions.to_csv('../output/prediction.txt', index=False)"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'learn': {'Accuracy': 0.84024, 'Logloss': 0.3674780978985}}\n"]}],"metadata":{}},{"cell_type":"markdown","source":["## One-hot encoding\n","The features labeled:\n","- f0 (Boolean)\n","- f1\n","- f2\n","- f4\n","- f9\n","- f10\n","- f13\n","- f18\n","- f22\n","- f25 (Boolean)\n","- f26 (Boolean)\n","\n","Toghether with the hex features discussed above:\n","- f8 \n","- f12 \n","- f14 \n","- f15 \n","- f23\n","\n","\n","All seem to be categorical and should therefore be converted to one-hot encoding (depending on the learning algorithm)."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# One-hot encode categorical features\n","categorical_features = ['f0', 'f1', 'f2', 'f4', 'f8', 'f9', 'f10', 'f12', 'f13', 'f14', 'f15', 'f18', 'f22', 'f23', 'f25', 'f26']\n","\n","X_encoded = pd.get_dummies(X, columns=categorical_features)\n","X_encoded.head()"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Normalize numerical "],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# Turn boolean and categorical features into type category\n","# boolean_features = ['f0', 'f25', 'f26']\n","# categorical_features = ['f1', 'f2', 'f4', 'f9', 'f10', 'f13', 'f18', 'f22']\n","# non_numeric_features = boolean_features + categorical_features\n","# \n","# X[non_numeric_features] = X[non_numeric_features].astype('category')\n","# X[boolean_features] = X[boolean_features].apply(lambda x: x.cat.codes)\n","# X[boolean_features[1:]] = X[boolean_features[1:]].replace({1: 0, 2: 1})\n","# \n","# # Turn categorical columns into categorical \n","# #categorical_features = ['f1', 'f2', 'f4', 'f9', 'f10', 'f13', 'f18', 'f22']\n","# #X_train[categorical_features] = X_train[categorical_features].astype(\"category\")\n","# #X_test[categorical_features] = X_test[categorical_features].astype(\"category\")\n","# \n","# print(X[boolean_features].head())\n","# print(X[boolean_features].nunique())"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:23:37.233395Z","iopub.execute_input":"2021-09-28T14:23:37.233709Z","iopub.status.idle":"2021-09-28T14:23:37.274283Z","shell.execute_reply.started":"2021-09-28T14:23:37.233675Z","shell.execute_reply":"2021-09-28T14:23:37.273153Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# fill_value = 0\n","# \n","# X_train.fillna(fill_value, inplace=True), X_test.fillna(fill_value, inplace=True)\n","# missing_values = pd.DataFrame(\n","#     {\n","#         '#nan_train': X_train.isnull().sum(axis = 0),\n","#         '#nan_test': X_test.isnull().sum(axis = 0),\n","#     }, \n","#     index=X_train.columns,\n","# )\n","# print(missing_values)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:50.121796Z","iopub.execute_input":"2021-09-28T14:03:50.122066Z","iopub.status.idle":"2021-09-28T14:03:50.128463Z","shell.execute_reply.started":"2021-09-28T14:03:50.122038Z","shell.execute_reply":"2021-09-28T14:03:50.12731Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# plt.figure(figsize=(32, 12))\n","# sns.heatmap(training_data.corr(), annot=True, cmap='viridis')"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:50.130459Z","iopub.execute_input":"2021-09-28T14:03:50.130688Z","iopub.status.idle":"2021-09-28T14:03:50.144133Z","shell.execute_reply.started":"2021-09-28T14:03:50.130663Z","shell.execute_reply":"2021-09-28T14:03:50.143259Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# # Cell for just testing out random stuff\n","# f8 = training_data[['f8']].fillna('0')\n","# print(f8.isnull().sum(axis = 0))\n","# print(f8.isna().sum(axis = 0))\n","# print(f8.dtypes)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:50.145143Z","iopub.execute_input":"2021-09-28T14:03:50.14535Z","iopub.status.idle":"2021-09-28T14:03:50.15857Z","shell.execute_reply.started":"2021-09-28T14:03:50.145326Z","shell.execute_reply":"2021-09-28T14:03:50.157546Z"},"trusted":true}},{"cell_type":"markdown","source":["## Feature engineering\n","The features labeled:\n","- f0 (0.0 or 1.0 / Boolean)\n","- f1\n","- f2\n","- f4\n","- f9\n","- f10\n","- f13\n","- f18\n","- f22\n","- f25 (Boolean)\n","- f26 (Boolean)\n","\n","All seem to be categorical and should be converted to numbers (depending on the learning algorithm).\n","\n","---\n","\n","The features labeled:\n","- f8 \n","- f12 \n","- f14 \n","- f15 \n","- f23\n","\n","All seem to be hexadecimal. These might just be an id of sorts, or they can be the hex representation of a number.  \n","An idea can be to covert these into decimal and see if they are important somehow."],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["radix = 16\n","hexadecimal_columns = ['f8', 'f12', 'f14', 'f15', 'f23']\n","\n","X = training_data.copy()\n","X[hexadecimal_columns] = X[hexadecimal_columns].fillna('-1').transform(lambda x: x.astype(str).map(lambda x: int(x, base=radix)))\n","X = X.replace(-1, float('nan'))\n","\n","print(X[hexadecimal_columns].nunique())\n","X[hexadecimal_columns].hist(bins=2203, figsize=(25, 15), layout=(2, 7))"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:50.159807Z","iopub.execute_input":"2021-09-28T14:03:50.160253Z","iopub.status.idle":"2021-09-28T14:03:50.17312Z","shell.execute_reply.started":"2021-09-28T14:03:50.160218Z","shell.execute_reply":"2021-09-28T14:03:50.172125Z"},"trusted":true}},{"cell_type":"markdown","source":["Converting categorical data to numbers"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["# categorical_columns = ['f1', 'f2', 'f4', 'f9', 'f10', 'f13', 'f18', 'f22', 'f25', 'f26']\n","\n","# transformed_training_data[categorical_columns] = transformed_training_data[categorical_columns].apply(lambda x: x.cat.codes)\n","# transformed_training_data"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-28T14:03:50.174269Z","iopub.execute_input":"2021-09-28T14:03:50.174514Z","iopub.status.idle":"2021-09-28T14:03:50.190434Z","shell.execute_reply.started":"2021-09-28T14:03:50.174487Z","shell.execute_reply":"2021-09-28T14:03:50.189511Z"},"trusted":true}},{"cell_type":"markdown","source":["# TODOS:\n","\n","* PrÃ¸ve Ã¥ konvertere null-verdier til 0, og Ã¥ ha null som en egen kategori\n","* Teste med bÃ¥de OHE og annen type category encoding "],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# Data exploration"],"metadata":{}}]}